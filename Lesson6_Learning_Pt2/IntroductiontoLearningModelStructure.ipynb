{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Learning Model Structure\n",
    "\n",
    "\n",
    "\n",
    "## CSCI E-83\n",
    "## Stephen Elston\n",
    "\n",
    "\n",
    "In the previous lesson we explored some approaches to learning model parameters. This discussion assumed that the model structure or skeleton was known. However, there are many cases where this structure may not be known a priori. In this lesson we will focus on algorithms for **learning model structure**. The role of learning in an intelligent agent is illustrated in the figure below.\n",
    "\n",
    "<img src=\"img/Learning.JPG\" alt=\"Drawing\" style=\"width:400px; height:200px\"/>\n",
    "<center> **Learning in an intelligent agent** </center>\n",
    "\n",
    "The goal of probabilistic network structure learning is to determine the independencies in the distribution of the data. The independencies determine the structure of the graph. Typically the goal is to minimize a measure of **divergence** between the distribution of the data and the distribution represented by the graph.  \n",
    "\n",
    "All methods for learning the structure of probabilistic graphical models are approximate and computationally intensive. At best, the learned structure is an approximation of the  Further, these algorithms require considerably more data than is required for inference. \n",
    "\n",
    "Some options for learning model structure include:\n",
    "\n",
    "- **Eliciting knowledge** from experts on the independencies of the distribution. However, this can be a tedious process for more than fairly simple problems. \n",
    "- Estimate the potentials of the graph though parameter estimation or **parameter learning** of the distributions. This approach assumes that we know these distributions. \n",
    "- Use learning to the structure of the graph, known as **structure learning**. As you will see, this approach will typically lead to an approximate solution, which may not capture the true independencies. \n",
    "\n",
    "Suggested readings for this lesson include the following, along with references contained herein:\n",
    "- Barber Section 9.5,\n",
    "- Murphy Section 26.1, 26.2, 26.3, 26.4. \n",
    "\n",
    "> **Note 1:** In this lesson we are only concerned with finding the structure of Bayesian networks or DAGS. Finding the structure of undirected Markov networks involves maximum likelihood methods, and can be considerably more difficult. For introductions to this problem see Barber Section 9.6 or Murphy Section 26.7. \n",
    "\n",
    "> **Note 2:** In this lesson we will only explore algorithms for finding structure of Bayesian or directed networks with complete data. We will not address the problems of finding the structure of networks with hidden or latent variables. These later problems are considerably harder to deal with and an area of on-going research. **Structural expectation-maximization** or **Structural EM** algorithms are typically used. For an overview of these methods see Murphy Section 26.5 or Barber Section 11.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems of Structure Estimation\n",
    "\n",
    "Finding graphical model the structure from data is a complex problem. The goal is to find a graph structure which best represents the independencies of the distribution of the data. This is accomplished by searching through possible graph structures. \n",
    "\n",
    "Finding graph structure can be used as data mining method. However, searching for graph structure is not without some serious pitfalls. The result is that any structure determined from a finite quantity of data is approximate at best. Interpretation of any relationships found in resulting graph structures should be done with caution. \n",
    "\n",
    "The pitfalls not withstanding, an approximately correct graph can provide useful inferences for many types of complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and Computational Complexity\n",
    "Let's explore the computational complexity of finding the structure of a graphical models. Consider the fully connected graph of the variables in the student model illustrated below.   \n",
    "\n",
    "<img src=\"img/FullyConneted.JPG\" alt=\"Drawing\" style=\"width:400px; height:250px\"/>\n",
    "<center> **Fully connected student graph** </center>\n",
    "\n",
    "There are quite a few possible edges between these variables. Consider the complexity of an algorithm that attempts to search all possible graphs for these variables. The complexity of this type of **exhaustive serach**:\n",
    "\n",
    "$$C(n) = n^{O(2^{O(n)})}$$\n",
    "\n",
    "You can see from the above relationship that exhaustive search is computationally infeasible for all but the smallest graph. This fact means that all practical structure finding algorithms are necessarily approximate.  \n",
    "\n",
    "In practice, structure search is performed using some combination of the following:\n",
    "1. **Constraints** on the search. A common constraint is on the number of parents of each node. Another common constraint is to assume the graph is a tree.\n",
    "2. Use of **search heuristics** to reduce the complexity of the search. There are many possibilities, several of which are used in other machine intelligence applications.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-equivelence and Ambiguity in Graph Structure Search\n",
    "\n",
    "In previous lessons we have seen that the graphs representing an I-map of a distribution are not unique. From another perspective, we can say that it is possible for several DAGs to exhibit Markov equivalence. These facts mean that there is ambiguity in the determination of graph structure from data. It should not come as a surprise that several DASs exhibit nearly the same fit to a set of data.  \n",
    "\n",
    "A further, and often more significant problem in practice, problem is that with limited amounts of data determination of independencies is error prone. In fact, it will often be the case that any pair of variables in a finite size dataset will show some dependencies. \n",
    "\n",
    "The above problems can be overcome in an approximate sense in several ways including:\n",
    "- Using constraints on the graph structure search. \n",
    "- Setting thresholds or using significance tests for determining independencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Algorithm\n",
    "\n",
    "One of the oldest algorithms for finding network structure is the **PC algorithm**. The PC algorithm is a locally greedy search algorithm for determining the structure of Bayesian networks. The PC algorithm is a two step process:\n",
    "\n",
    "- The skeleton of the graph is determined.\n",
    "- The direction of the edges is determined.\n",
    "\n",
    "The PC algorithm uses **constraint satisfaction search** methods. Constraint satisfaction search is a classic artificial intelligence learning method. The constraint satisfaction search problem predates the computer era. Frances Guthrie applied the method to the 4 color map problem in 1852. Constraint satisfaction search methods were applied in artificial intelligence starting in the early 1960s. For readable discussion of the constraint satisfaction search methods in artificial intelligence see Chapter 6 of Russell and Norvig, third edition. \n",
    "\n",
    "The determination of the skeleton can be done in a number of ways. One approach is using greedy elimination:\n",
    "\n",
    "- Start with a fully connected network. \n",
    "- Find the a connection with $x \\bot y\\ |\\ \\oslash$ using a **mutual information criteria**. That is $x$ and $y$ are independent. A Chi Squared significance test is used to determine set a cut-off for independence.\n",
    "- Repeat the above step until the algorithm terminates when the number of connections per node is at or below a predetermined threshold. \n",
    "\n",
    "With the skeleton determined, the directions of the edges must be determined. For three variables $x$, $y$ and $z$ this can be done using the independencies:\n",
    "\n",
    "$$x \\bot y\\ |\\ \\oslash \\Rightarrow x\\ y\\ are\\ parents\\ of\\ z$$\n",
    "\n",
    "or  \n",
    "\n",
    "$$x \\bot y\\ |\\ z \\Rightarrow z\\ is\\ parent\\ of x\\ and\\ y$$\n",
    "\n",
    "In practice, the PC algorithm is mostly of historical interest and has inferior performance to newer algorithms.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climb Search\n",
    "\n",
    "A commonly used search method is **hill climbing**, also known as the **method of steepest ascent**. Hill climbing is applied in a number of  There are a number of variations. In general, this search method is a **locally greedy** approach to improving an **objective function**, $f(x)$. \n",
    "\n",
    "To determine the structure of graphical models, the objective function is some measure of the **divergence** between the distribution of the data and the distribution represented by the graph. Finding graph structure is a search of discrete states. These states correspond to the presence or absence of edges between the nodes.    \n",
    "\n",
    "The hill climb search proceeds through a series of discrete states to find the terminal state. The search continues until the improvement in the objective function is less than some threshold. There are several commonly used variants to find the locally greedy improvement including:\n",
    "1. The closest state which improves the the objective function is taken as the next step.  \n",
    "2. The successor state with the largest possible improvement is taken at each step.   \n",
    "\n",
    "As with all locally greedy methods, hill climb search can become stuck at **local optimum**. Some more sophisticated variations use stochastic sampling methods to try to overcome this problem. \n",
    "\n",
    "Additional details on the hill climbing algorithm can be found in Section 4.1.1 of Russell and Norvig, third edition. \n",
    "\n",
    "> **Note:** Another commonly used search method is tabu search. This algorithm was developed by Fred Glover in the late 1980s as a mixed integer programming method. For many, but not all, problems tabu search can outperform hill climbing. Tabu search keeps a list of already visited states and prevents the algorithm from revisiting these states. Further, tabu search will accept moves that decrease the objective function if all other states are blocked. In this way, tabu search promotes **exploration** of the space. However, maintaining the tabu list can require prohibitive amounts of memory. You can find a readable introduction to this algorithm in [the Wikipedia article](https://en.wikipedia.org/wiki/Tabu_search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Scoring and the Bayesian Information Criteria\n",
    "\n",
    "Having discussed the general approach to searching for Bayesian graph structure, let's look at a specific example of scoring a model. We can compute a score for a graph, $\\mathcal{G}$, in a general form: \n",
    "\n",
    "$$Score(G:D) = log \\big(\\mathcal{L}(G:D) \\big) - \\phi( n ) \\parallel G \\parallel\\\\\n",
    "where\\\\\n",
    "\\mathcal{L}(G:D) = likelihood\\\\\n",
    "n = number\\ of\\ samples\\\\\n",
    "\\parallel G \\parallel = number\\ of\\ parameters\\ in\\ \\mathcal{G}$$\n",
    "\n",
    "The **Baysian Information Criteria** or **BIC** is a widely used scoring function. It is closely related to the Akaike Information Criteria (AIC). The BIC was proposed by Gideon Schwarz in 1978, and is sometimes referred to as the Schwarz Information Criteria. The . We can write the BIC in the form above as:\n",
    "\n",
    "$$BIC = ln(n) \\parallel G \\parallel- 2\\ ln \\big (\\mathcal{L}(G:D) \\big)\\\\\n",
    "where\\\\\n",
    "\\mathcal{L} = the\\ likelihood\\ given\\ the\\ fitted\\ graph\\ parmaters\\\\\n",
    "D = observed\\ data\\\\\n",
    "\\parallel G \\parallel = number\\ of\\ model\\ parameters\\\\\n",
    "n = number\\ of\\ observations$$\n",
    "\n",
    "A few comments on BIC:\n",
    "- The higher the likelihood, the lower the BIC. Models with lower BIC are considered better. \n",
    "- The larger the number of parameters the higher the BIC. Thus, BIC penalizes complex models and prefers simple models with few edges.  \n",
    "\n",
    "BIC is used a model scoring method in conjunction with a search method. For example, the BIC can be used as an objective function for determining if an edge should or should not be in the graph. Strictly speaking, the negative of the BIC is used with the hill climbing algorithm. \n",
    "\n",
    "> **Note:** Despite its name the Bayesian Information Criteria is in no way Bayesian. There is no prior distribution. Further, the result is a score, which cannot be interpreted as a probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Computational Example\n",
    "\n",
    "Having discussed the theory of finding graph structure by model scoring, let's try a computational example. We will continue to work with the student example illustrated below:\n",
    "\n",
    "<img src=\"img/LetterDAG.JPG\" alt=\"Drawing\" style=\"width:400px; height:200px\"/>\n",
    "<center> **DAG CPDs for student example** </center>\n",
    "\n",
    "In this example we will perform the following:\n",
    "\n",
    "1. Simulate data for the CPDs of the model.\n",
    "2. Find the BIC score using the structure used for the simulation.\n",
    "3. Estimate the graph structure.\n",
    "4. Compare the BIC score for the computed graph structure to the BIC score of the structure used for the simulation. \n",
    "\n",
    "Execute the code in the cell below to create 250 cases of simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>G</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I  D    S  G  L\n",
       "0  1  1  0.0  1  1\n",
       "1  1  1  1.0  2  0\n",
       "2  0  1  0.0  2  0\n",
       "3  1  1  1.0  0  1\n",
       "4  0  1  0.0  2  0\n",
       "5  0  0  1.0  1  0\n",
       "6  0  1  0.0  1  0\n",
       "7  1  1  1.0  0  1\n",
       "8  1  1  1.0  0  0\n",
       "9  1  0  1.0  0  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Simulate the binary tables\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import pandas as pd\n",
    "\n",
    "nsamp = 250\n",
    "\n",
    "def sim_bernoulli(p, n = 25):\n",
    "    \"\"\"\n",
    "    Function to compute the vectors with probabilities for each \n",
    "    condition (input value) of the dependent variable using the Bernoulli\n",
    "    distribution. \n",
    "    \n",
    "    The arguments are:\n",
    "    p - a vector of probabilites of success for each case.\n",
    "    n - The numer of realizations. \n",
    "    \"\"\"\n",
    "    temp = np.zeros(shape = (len(p), n))\n",
    "    for i in range(len(p)): \n",
    "        temp[i,:] = nr.binomial(1, p[i], n)\n",
    "    return(temp)\n",
    "\n",
    "def selec_dist_1(sims, var, lg):\n",
    "    \"\"\"\n",
    "    Function to integrate the conditional probabilities for\n",
    "    each of the cases of the parent variable. \n",
    "    \n",
    "    The arguments are:\n",
    "    sims - the array of simulated realizations with one row for each state of the\n",
    "           parent variable. \n",
    "    var - the vector of values of parent variable used to select the value from the \n",
    "          sims array.\n",
    "    lg - vector of states of possible states of the parent variable. These must be\n",
    "         in the same order as for the sims array. \n",
    "    \"\"\"\n",
    "    out = sims[0,:] # Copy of values for first parent state\n",
    "    var = np.array(var).ravel()\n",
    "    for i in range(1, sims.shape[0]): # loop over other parent states\n",
    "        out = [x if u == lg[i] else y for x,y,u in zip(sims[i,:], out, var)]\n",
    "    return([int(x) for x in out])\n",
    "\n",
    "def set_class(x):\n",
    "    \"\"\"\n",
    "    Function to flatten the array produced by the numpy.random.multinoulli function. \n",
    "    The function tests which binary value of the array of output states is true\n",
    "    and substitutes an integer for that state. This function only works for up to three\n",
    "    output states. \n",
    "    \n",
    "    Argument:\n",
    "    x - The array produced by the numpy.random.multinoulli function. \n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i,j in enumerate(x):\n",
    "        if j[0] == 1: out.append(0)\n",
    "        elif j[1] == 1: out.append(1)\n",
    "        else: out.append(2)   \n",
    "    return(out)   \n",
    "\n",
    "\n",
    "def sim_multinoulli(p, n = 25):\n",
    "    \"\"\"\n",
    "    Function to compute the vectors with probabilities for each \n",
    "    condition (input value) of the dependent variable using the multinoulli\n",
    "    distribution. \n",
    "    \n",
    "    The arguments are:\n",
    "    p - an array of probabilites of success for each possible combination\n",
    "        of states of the parent variables. Each row in the array are the \n",
    "        probabilities for each state of the multinoulli distribution for \n",
    "        that combination of parent values.\n",
    "    n - The numer of realizations. \n",
    "    \"\"\"\n",
    "    temp = np.zeros(shape = (p.shape[0], n))\n",
    "    for i in range(p.shape[0]): \n",
    "        ps = p[i,:]\n",
    "        mutlis = nr.multinomial(1, ps, n) \n",
    "        temp[i,:] = set_class(mutlis)\n",
    "    return(temp)\n",
    "\n",
    "def selec_dist_2(sims, var1, var2, lg1, lg2):\n",
    "    \"\"\"\n",
    "    Function to integrate the conditional probabilities for\n",
    "    each of the cases of two parent variables. \n",
    "    \n",
    "    The arguments are:\n",
    "    sims - the array of simulated realizations with one row for each state of the\n",
    "           union of the parent variables. \n",
    "    var1 - the vector of values of first parent variable used to select the value from the \n",
    "          sims array.\n",
    "    var2 - the vector of values of second parent variable used to select the value from the \n",
    "          sims array.\n",
    "    lg1 - vector of states of possible states of the first parent variable. These must be\n",
    "         in the same order as for the sims array. \n",
    "    lg2 - vector of states of possible states of the second parent variable. These must be\n",
    "         in the same order as for the sims array. \n",
    "    \"\"\"\n",
    "    out = sims[0,:] # Copy values for first combination of states for parent variables\n",
    "    ## make sure the parent variables are 1-d numpy arrays.\n",
    "    var1 = np.array(var1).ravel() \n",
    "    var2 = np.array(var2).ravel()\n",
    "    for i in range(1, sims.shape[0]): # Loop over all comnination of states of the parent variables\n",
    "        out = [x if u == lg1[i] and v == lg2[i] else y for x,y,u,v in zip(sims[i,:], out, var1, var2)]\n",
    "    return([int(x) for x in out])\n",
    "\n",
    "\n",
    "## First the conditionally independent variables\n",
    "nr.seed(22234)\n",
    "D_samps = pd.DataFrame(nr.binomial(1, 0.7, nsamp), columns = ['D'])\n",
    "nr.seed(2355)\n",
    "I_samps = pd.DataFrame(nr.binomial(1, 0.8, nsamp), columns = ['I'])\n",
    "\n",
    "## The variable conditional on two others and with three possible states\n",
    "probs = np.array([[0.3, 0.05, 0.8,  0.5], [0.4, 0.25, 0.15, 0.3], [0.3, 0.7,  0.05, 0.2]]).transpose()\n",
    "nr.seed(2334)\n",
    "sims = sim_multinoulli(probs, nsamp)\n",
    "I_lg = [0,0,1,1]\n",
    "D_lg = [0,1,0,1]\n",
    "G_samps = pd.DataFrame(selec_dist_2(sims, I_samps, D_samps, I_lg, D_lg), columns = ['G'])\n",
    "\n",
    "## Finally, the two variables conditionally depenent on one other\n",
    "probs = [0.9, 0.6, 0.1]\n",
    "nr.seed(2134)\n",
    "bern = sim_bernoulli(probs, nsamp)\n",
    "L_samps = pd.DataFrame(selec_dist_1(bern, G_samps, [0,1,2]), columns = ['L'])\n",
    "\n",
    "probs = [0.2, 0.8]\n",
    "nr.seed(22234)\n",
    "bern = sim_bernoulli(probs)\n",
    "S_samps = pd.DataFrame(selec_dist_1(bern, I_samps, [0,1]), columns = ['S'])\n",
    "\n",
    "## Now concatenate the columns into one data frame\n",
    "dats = pd.concat([I_samps, D_samps, S_samps, G_samps, L_samps], axis = 1)\n",
    "print(dats.shape)\n",
    "dats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data simulated, we can create a DAG using the known structure and compute the BIC score. Execute the code in the cell below and note the BIC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-87.50440751623961\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore, K2Score, StructureScore\n",
    "from pgmpy.models import BayesianModel\n",
    "\n",
    "model_1 = BayesianModel([('D','G'), ('I','S'), ('I','G'),('G','L')])\n",
    "print(BicScore(dats).score(model_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below uses hill climbing search with the BIC score as the objective function to estimate the skeleton of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'G', 'I', 'L', 'S']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_bic = HillClimbSearch(dats, scoring_method=BicScore(dats))\n",
    "bic_model = est_bic.estimate()\n",
    "sorted(bic_model.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below estimates the structure of the belief network. The search is constrained so that a node may have no more than two edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'D'), ('D', 'L'), ('L', 'G'), ('L', 'S')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIC_edges = est_bic.estimate(max_indegree=2).edges()\n",
    "BIC_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure discovered is a simple linear graph. This result is not exactly what might be expected. This structure can be tested by computing the BIC score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-42.87809563669704\n"
     ]
    }
   ],
   "source": [
    "model_2 = BayesianModel(BIC_edges)\n",
    "print(BicScore(dats).score(model_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the BIC score has increased considerably from the graph structure used to simulate the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The K2 Score method\n",
    "\n",
    "Another approach to model scoring is the **K2 algorithm** or **K2 score method**. The K2 algorithm uses a greedy search, such as hill climbing, and proceeds by the following steps:   \n",
    "1. The nodes are ordered. The search will follow this ordering.   \n",
    "2. The search begins begins with the first node in the order, which initially has no parents.   \n",
    "3. Parents are added incrementally in the order that the action increases the score the most.  \n",
    "4. The search terminates when the score no longer increases. \n",
    "\n",
    "A number of scoring metrics have been used with the K2 algorithm. The most commonly used is the **Bayesian score**. For a graph, $\\mathcal{G}$, and $n$ dimensional data $D$ sampled from the joint distribution we can apply Bayes' theorem:\n",
    "\n",
    "$$p(D\\ |\\ \\mathcal{G}) = \\frac{p(\\mathcal{G}\\ |\\ D) p(\\mathcal{G})}{p(D)} = \\frac{p(\\mathcal{G}, D)}{p(D)}$$\n",
    "\n",
    "The prior distribution, , is typically a uniform Dirichlet, unless we have some reason to bias the solution toward a particular structure. \n",
    "\n",
    "Since $p(D)$ is the same for all graph structures we can use either the marginal likelihood, p(\\mathcal{G}\\ |\\ D), or the joint posterior probability distribution.\n",
    "\n",
    "We can assume the parameters associated with each variable in the graph are independent, the K2 metric can be decomposed:\n",
    "\n",
    "$$p(\\mathcal{G}, D) = p(\\mathcal{G}) \\prod_{i=1}^n g(d_i, \\mathbf{P_{a_i}})\\\\ \n",
    "where\\\\\n",
    "g(d_i, \\mathbf{P_{a_i}}) = subscore\\ of\\ ith\\ dimension$$\n",
    "\n",
    "This decomposition allows the search algorithm to find the maximum score variable by variable. \n",
    "\n",
    "The requirement to select a good search order of the nodes can lead to difficulties applying the K2 algorithm in practice. A number of random starts can be used to used to try different node orderings. \n",
    "\n",
    "An advantage of the K2 method is that no restrictions need be applied to the number of parents of a node. The constraints for the search arise from the initial node ordering. \n",
    "\n",
    "A more complete discussion of the K2 algorithm can be found in the [paper by Lerner and Malka](http://www.ee.bgu.ac.il/~boaz/LernerMalkaAAI2011.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-56.82276673529562\n"
     ]
    }
   ],
   "source": [
    "print(K2Score(dats).score(model_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'G', 'I', 'L', 'S']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_K2S = HillClimbSearch(dats, scoring_method=K2Score(dats))\n",
    "K2S_model = est_K2S.estimate()\n",
    "sorted(K2S_model.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'D'), ('D', 'L'), ('G', 'S'), ('L', 'G')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_K2S.estimate(max_indegree=2).edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-45.63882609562817\n"
     ]
    }
   ],
   "source": [
    "model_3 = BayesianModel(est_K2S.estimate(max_indegree=2).edges())\n",
    "print(BicScore(dats).score(model_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Information Theory\n",
    "\n",
    "In order to find an optimal structure for a Bayesian directed graphical model we need to have a loss **loss function**, also known as a **cost function**. In simple terms, the loss function measures how well the graphical model represents the available data. The lower the loss, the better the fit. \n",
    "\n",
    "### Shannon Entropy\n",
    "\n",
    "As a first step in understanding information theory we need to define **Shannon entropy**:\n",
    "\n",
    "$$\\mathbb{H}(I) = E[I(X)] = E[-ln_b(P(X))] = - \\sum_{i=1}^n P(x_i) ln_b(P(x_i)$$  \n",
    "Where:  \n",
    "$E[X] = $ the expectation of $X$.  \n",
    "$I(X) = $ the information content of $X$.   \n",
    "$P(X) = $ probabiliy of $X$.  \n",
    "$b = $ base of the logrithm.    \n",
    "\n",
    "This rather abstract formula gives us a way to compute the expected information content of a vector of observations $X$. The more likely (higher probability) $X$ is the less informative it is. In other words, unexpected observations carry the most information.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "7\n",
      "1000\n",
      "0.06157894736842105\n",
      "50\n",
      "1000\n",
      "0.1131578947368421\n",
      "109\n",
      "1000\n",
      "0.16473684210526315\n",
      "173\n",
      "1000\n",
      "0.2163157894736842\n",
      "218\n",
      "1000\n",
      "0.26789473684210524\n",
      "236\n",
      "1000\n",
      "0.3194736842105263\n",
      "309\n",
      "1000\n",
      "0.37105263157894736\n",
      "361\n",
      "1000\n",
      "0.4226315789473684\n",
      "405\n",
      "1000\n",
      "0.47421052631578947\n",
      "478\n",
      "1000\n",
      "0.5257894736842105\n",
      "527\n",
      "1000\n",
      "0.5773684210526315\n",
      "580\n",
      "1000\n",
      "0.6289473684210526\n",
      "650\n",
      "1000\n",
      "0.6805263157894736\n",
      "680\n",
      "1000\n",
      "0.7321052631578947\n",
      "703\n",
      "1000\n",
      "0.7836842105263158\n",
      "783\n",
      "1000\n",
      "0.8352631578947368\n",
      "850\n",
      "1000\n",
      "0.8868421052631579\n",
      "879\n",
      "1000\n",
      "0.9384210526315789\n",
      "937\n",
      "1000\n",
      "0.99\n",
      "981\n",
      "1000\n",
      "[1.945910149055313, 3.9120230054281464, 4.6913478822291435, 5.153291594497778, 5.384495062789089, 5.46383180502561, 5.733341276897745, 5.888877958332882, 6.003887067106539, 6.1696107324914555, 6.267200548541362, 6.363028103540465, 6.476972362889683, 6.522092798170152, 6.555356891810664, 6.663132695990805, 6.745236349484361, 6.778784897685176, 6.842683282238424, 6.888572459565361]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def entp(dat):\n",
    "    print(np.sum(dat))\n",
    "    print(dat.size)\n",
    "#    p_dat = np.sum(dat)/dat.size # calculates the probabilities\n",
    "    return(entropy(dat))  # input probabilities to get the entropy \n",
    "\n",
    "entrops = []\n",
    "for p in np.linspace(0.01, 0.99, 20):\n",
    "    print(p)\n",
    "    temp = nr.binomial(1, p, size=1000)\n",
    "    entrops.append(entp(temp))\n",
    "\n",
    "print(entrops)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback-Leibler Divergence\n",
    "\n",
    "To create a loss function from the definition of Shannon entropy we start with the **Kullback-Leibler divergence (KL divergence)** or **relative entropy**. The KL divergence is an information theoretic measure of the difference between two distributions, $P(X)$ and $Q(X)$.\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P|Q) = - \\sum_{i=1}^n p(x_i)\\ ln_b \\frac{p(x_i)}{q(x_i)}$$\n",
    "\n",
    "Ideally, in the case of training a machine learning model we want a distribution $Q(X)$, which is identical to the actual data distribution $P(X)$. In this case the KL divergence is 0 since:\n",
    "\n",
    "$$ln (\\frac{p(x_i)}{q(x_i)}) = ln(1) = 0$$\n",
    "\n",
    "But, you may say, if we could know $P(X)$ why compute $Q(X)$ at all? Fortunately, we do not have to. We can rewrite the KL divergence as:\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P|Q) = \\sum_{i=1}^n p(x_i)\\ ln_b \\big(p(x_i) \\big) - \\sum_{i=1}^n p(x_i)\\ ln_b \\big( q(x_i) \\big)$$\n",
    "\n",
    "where, $\\mathbb{H}(p,q)$ is the cross entropy:\n",
    "\n",
    "$$\\mathbb{H}(p,q) = -\\sum_k p_k log(q_k)$$ \n",
    "\n",
    "Here, $ln_b$ is the log base 2 logarithm. Using base 2 gives KL divergence units of bits. \n",
    "\n",
    "Since $P(X)$ is fixed and we wish to find $Q(X)$ when we train our model, we can minimize the term on the right, which is the **cross entropy** defined as:\n",
    "\n",
    "$$\\mathbb{H}(P,Q) = - \\sum_{i=1}^n p(x_i)\\ ln_b q(x_i)$$\n",
    "\n",
    "From the formulation of KL divergence above you can see the following.\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P|Q) = \\mathbb{H}(P) + \\mathbb{H}(P,Q)\\\\\n",
    "\\mathbb{D}_{KL}(P|Q) = Entropy(P) + Cross\\ Entropy(P,Q)$$\n",
    "\n",
    "Thus, we can minimize divergence by minimizing cross entropy. This idea is both intuative and compuationally attractive. The closer the estimated distribution $q(X)$ is to the distribution of the true underling process $p(X)$, the lower the cross entropy and the lower the KL divergence. \n",
    "\n",
    "In general we will not know $p(X)$. In fact, if we did, why would we need to solve a training problem? So, we can use the following approximation.\n",
    "\n",
    "$$\\mathbb{H}(P,Q) = - \\frac{1}{N} \\sum_{i=1}^n ln_b q(x_i)$$\n",
    "\n",
    "You may notice, that this approximation, using the average log likelihood, is equivelent to a maximum likelihood estimator (MLE). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information\n",
    "\n",
    "There is one other information theoretic concept we must address, **mutual information**. Conceptually, mutual information between two variables measures how much knowing the value of one variable tells us about the other. Quantitatively, we can express mutual information as follows:\n",
    "\n",
    "$$I(X;Y) = \\sum_{y \\in Y} \\sum_{x \\in X} p(x,y) log \\Big( \\frac{p(x,y}{p(x) p(y)} \\Big)$$ \n",
    "\n",
    "We can gain some intuition by considering the value of $I(X;Y)$ when the two distributions are independently distributed. In this case:\n",
    "\n",
    "$$log \\Big( \\frac{p(x,y}{p(x) p(y)} \\Big) = log(1) = 0$$\n",
    "\n",
    "In words, when $p(x)$ and $p(y)$ are independent there is no mutual information. \n",
    "\n",
    "Mutual information has several important properties. The first property is that mutual information must be greater than or equal to zero; $I(X;Y) \\ge 0$. Second, mutual information is symmetric: $I(X;Y) = I(Y;X)$. We can also relate mutual information to entropy, conditional entropy and joint entropy as follows:\n",
    "\n",
    "$$I(X;Y) \\equiv H(X) - H(X\\ |\\ Y) \\equiv H(Y) - H(Y\\ |\\ X) \\\\\n",
    "\\equiv H(X) + H(Y) - H(X,Y)$$\n",
    "\n",
    "Finally, the mutual information, $I(X;Y)$, is the Kullback-Leibler divergence between the product of $p(x)$ and $p(y)$ and the joint distribution $p(x,y)$: \n",
    "\n",
    "$$I(X;Y) = D_{KL}(p(x,y) \\parallel p(x)\\ p(y))$$\n",
    "\n",
    "Intuitively, the greater this divergence the more information available on one variable given the other. Likewise, if $p(x)$ and $p(y)$ are independent the KL divergence with respect to the joint distribution is 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Chow-Liu Tree Algorithm\n",
    "\n",
    "The Chow-Liu algorithm is an information theoretic approach to finding the structure of probabilistic models. The idea is to find a tree structure for the graph that best fits the distribution as measured by the KL divergence. The Chow-Liu tree algorithm has some practical advantages over many heuristic methods, since it is guaranteed to converge. \n",
    "\n",
    "The KL divergence for a DAG with a distribution, $q(x)$, representing an unknown distribution, $p(x)$, with $D$ variables,becomes:\n",
    "\n",
    "$$KL(p  \\parallel q) = \\langle log(p(x)) \\rangle_{p(x)} - \\sum_{i=1}^D \\langle log(q(x_i\\ |\\ x_{pa(i)}) \\rangle_{p(x_i,x_{pa(i)}}$$\n",
    "where the angle bracket notation, $\\langle\\ \\rangle$, indicates the expectation over the distribution. \n",
    "\n",
    "The for any two variables in the distribution, $x_i$ and $x_j$  mutual information is:\n",
    "\n",
    "$$MI(x_i, x_j) = \\Big\\langle log \\Big( \\frac{p(x_i,p_j)}{p(x_i)\\ p(x_j)} \\Big) \\Big\\rangle$$\n",
    "\n",
    "After some considerable algebra (see Section 9.5.4 and many other sources for details) we can now write the KL divergence of the tree as:\n",
    "\n",
    "$$KL(p  \\parallel q) = -\\sum_{i=1}^D MI(x)i;x_{pa(i)})   - \\langle log(p(x_i)) \\rangle_{p(x_i)} + Const$$\n",
    "\n",
    "The second term depends only on $p(x)$ and the third term is a constant. Thus minimizing $KL(p  \\parallel q)$ is the same as maximizing $\\sum_{i=1}^D MI(x)i;x_{pa(i)})$.  \n",
    "\n",
    "Maximizing the mutual information seems like a straight forward approach to finding graphical model structure. However, this problem is under-constrained. For finite sized datasets, the mutual information between any pair of variables in unlikely to be $0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>D</th>\n",
       "      <th>S</th>\n",
       "      <th>G</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I  D    S  G  L\n",
       "0  1  1  0.0  1  1\n",
       "1  1  1  1.0  2  0\n",
       "2  0  1  0.0  2  0\n",
       "3  1  1  1.0  0  1\n",
       "4  0  1  0.0  2  0\n",
       "5  0  0  1.0  1  0\n",
       "6  0  1  0.0  1  0\n",
       "7  1  1  1.0  0  1\n",
       "8  1  1  1.0  0  0\n",
       "9  1  0  1.0  0  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsamp = 250\n",
    "\n",
    "## First the conditionally independent variables\n",
    "nr.seed(22234)\n",
    "D_samps = pd.DataFrame(nr.binomial(1, 0.7, nsamp), columns = ['D'])\n",
    "nr.seed(2355)\n",
    "I_samps = pd.DataFrame(nr.binomial(1, 0.8, nsamp), columns = ['I'])\n",
    "\n",
    "## The variable conditional on two others and with three possible states\n",
    "probs = np.array([[0.3, 0.05, 0.8,  0.5], [0.4, 0.25, 0.15, 0.3], [0.3, 0.7,  0.05, 0.2]]).transpose()\n",
    "nr.seed(2334)\n",
    "sims = sim_multinoulli(probs, nsamp)\n",
    "I_lg = [0,0,1,1]\n",
    "D_lg = [0,1,0,1]\n",
    "G_samps = pd.DataFrame(selec_dist_2(sims, I_samps, D_samps, I_lg, D_lg), columns = ['G'])\n",
    "\n",
    "## Finally, the two variables conditionally depenent on one other\n",
    "probs = [0.9, 0.6, 0.1]\n",
    "nr.seed(2134)\n",
    "bern = sim_bernoulli(probs, nsamp)\n",
    "L_samps = pd.DataFrame(selec_dist_1(bern, G_samps, [0,1,2]), columns = ['L'])\n",
    "\n",
    "probs = [0.2, 0.8]\n",
    "nr.seed(22234)\n",
    "bern = sim_bernoulli(probs)\n",
    "S_samps = pd.DataFrame(selec_dist_1(bern, I_samps, [0,1]), columns = ['S'])\n",
    "\n",
    "## Now concatenate the columns into one data frame\n",
    "dats = pd.concat([I_samps, D_samps, S_samps, G_samps, L_samps], axis = 1)\n",
    "print(dats.shape)\n",
    "dats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'G', 'I', 'L', 'S']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'D'), ('D', 'L'), ('L', 'G'), ('L', 'S')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_bic = HillClimbSearch(dats, scoring_method=BicScore(dats))\n",
    "bic_model = est_bic.estimate()\n",
    "print(sorted(bic_model.nodes()))\n",
    "est_bic.estimate(max_indegree=2).edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2018, Stephen F Elston. All rights reserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
